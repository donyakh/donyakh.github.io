<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="description" content="AI and Computer Vision Scientist - Résumé for Donya Khaledyan" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Donya Khaledyan - Resume</title>
  <!-- Google Font Import -->
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;600;700&display=swap');

    /* Base resets and body styling */
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: 'Open Sans', Arial, sans-serif;
      background-color: #333;
      color: #f5f5f5;
      line-height: 1.6;
      margin: 0;
      position: relative;
    }

    /* Sticky navigation bar */
    .navbar {
      position: sticky;
      top: 0;
      background-color: #444;
      display: flex;
      justify-content: center;
      padding: 10px 0;
      z-index: 999;
      box-shadow: 0 2px 4px rgba(0, 0, 0, 0.4);
    }

    .navbar a {
      color: #f5f5f5;
      text-decoration: none;
      margin: 0 15px;
      font-weight: 600;
      transition: color 0.3s ease;
    }

    .navbar a:hover {
      color: #0fc451;
    }

    /* Container to center content on wider screens */
    .container {
      max-width: 900px;
      margin: 0 auto;
      padding: 20px 20px 80px; /* Extra bottom padding for scroll-to-top button */
    }

    /* Header section */
    header {
      text-align: center;
      margin-bottom: 20px;
      position: relative;
    }

    header h1 {
      color: #007BFF;
      font-size: 2.5rem;
      margin-bottom: 8px;
    }

    header p {
      font-size: 1rem;
    }

    /* Profile image */
    .profile-image {
      position: absolute;
      top: 20px;
      right: 20px;
      width: 160px;
      border-radius: 50%;
      object-fit: cover;
      box-shadow: 0 0 10px rgba(0,0,0,0.5);
    }

    /* Common section styling */
    section {
      margin-bottom: 40px;
    }

    .section-title {
      color: #0062cc;
      font-size: 1.5rem;
      margin: 30px 0 10px;
      padding-bottom: 5px;
      border-bottom: 2px solid #0062cc;
    }

    /* Content spacing */
    section p,
    section ul {
      margin-left: 20px;
      margin-bottom: 15px;
    }

    section ul li {
      margin-bottom: 5px;
    }

    /* Sub-headers (Experience, etc.) */
    h3 {
      color: #0fc451;
      margin-left: 20px;
      margin-top: 20px;
      margin-bottom: 10px;
      font-weight: 600;
    }

    /* Skills styling */
    .skills-list {
      list-style: none;
      padding: 0;
      margin-left: 20px;
    }

    .skills-list li {
      margin-bottom: 20px;
    }

    .skill-label {
      background-color: #007BFF;
      color: #2b2727;
      padding: 8px 12px;
      border-radius: 5px;
      display: inline-block;
      margin-bottom: 5px;
    }

    .bar-container {
      width: 100%;
      background-color: #444;
      border-radius: 5px;
      overflow: hidden;
      margin-top: 5px;
      /* transition for animation effect */
      transition: background-color 0.3s;
    }

    .bar {
      height: 20px;
      line-height: 20px;
      text-align: center;
      color: #fff;
      background-color: #0fc451;
      /* animate skill bar fill */
      transition: width 1s ease-in-out;
    }

    /* Hover effect for skill container (optional) */
    .bar-container:hover {
      background-color: #555;
    }

    /* Link styling */
    a {
      color: #0fc451;
      text-decoration: none;
      transition: color 0.3s;
    }
    a:hover {
      color: #00a851;
    }

    /* Scroll-to-top button */
    .scroll-to-top {
      position: fixed;
      bottom: 20px;
      right: 20px;
      background-color: #0fc451;
      color: #fff;
      border: none;
      border-radius: 4px;
      padding: 10px 15px;
      cursor: pointer;
      font-size: 14px;
      display: none; /* Hidden by default; shown with JS */
      box-shadow: 0 2px 6px rgba(0, 0, 0, 0.4);
      transition: background-color 0.3s;
    }
    .scroll-to-top:hover {
      background-color: #009b3f;
    }

    /* Responsive design adjustments */
    @media (max-width: 768px) {
      .profile-image {
        position: static;
        display: block;
        margin: 0 auto 20px auto;
      }
      .navbar {
        flex-wrap: wrap;
      }
      .navbar a {
        margin: 5px;
      }
      .section-title {
        font-size: 1.25rem;
      }
    }
  </style>
</head>
<body>

  <!-- Sticky Navbar -->
  <nav class="navbar">
    <a href="#summary">Summary</a>
    <a href="#skills">Skills</a>
    <a href="#proficiency">Proficiency</a>
    <a href="#experience">Experience</a>
    <a href="#Publications">Selected Publications</a>
    <a href="#education">Education</a>
    <a href="#teaching">Teaching</a>
  </nav>


  <div class="container">
    <header>
      <h1>Donya Khaledyan</h1>
      <p>Rochester, NY | dkhaledy@ur.rochester.edu</p>
    </header>

    <!-- FIND ME -->
    <section>
      <h2 class="section-title">Find Me</h2>
      <ul>
        <li><a href="https://www.linkedin.com/in/donya-khaledyan-b15623108/" target="_blank">LinkedIn</a></li>
        <li><a href="https://scholar.google.com/citations?user=jf_nkiEAAAAJ&hl=en" target="_blank">Google Scholar</a></li>
        <li><a href="https://github.com/donyakh" target="_blank">GitHub</a></li>
      </ul>
    </section>

    <!-- PROFESSIONAL SUMMARY -->
    <section id="summary">
      <h2 class="section-title">Professional Summary</h2>
      <p>
        AI and Computer Vision Scientist with 6+ years of experience specializing in deep learning, 
        computational imaging, hardware design, and model optimization (hardware and software). Expertise in image processing, signal processing, 
        and medical imaging workflows, with hands-on experience in FPGA and hardware implementation, and real-time algorithm development. Proven track record of building scalable AI systems 
        and integrating ML/GenAI into clinical pipelines. Strong background in multimodal deep learning, 
        generative AI (GANs, VAEs, Diffusion Models), and optimization techniques.
      </p>
    </section>

    <!-- KEY SKILLS -->
    <section id="skills">
      <h2 class="section-title">Key Skills</h2>
      <ul>
        <li><strong>Programming:</strong> Python, MATLAB, C, C++, VHDL, Verilog, Assembly.</li>
        <li><strong>Data Science & HPC:</strong> TensorFlow, PyTorch, Pandas, CUDA, cuDNN, Slurm.</li>
        <li><strong>Deep Learning & AI:</strong> CNNs, NLP (RNN, LSTM, Transformers), LLMs (Llama, BERT, GPT), Generative AI (GANs, VAEs, Transformers, Diffusions), Multimodal AI.</li>
        <li><strong>Machine Learning:</strong> KNN, SVM, Decision Trees, Random Forest, Bayesian Networks.</li>
        <li><strong>Computer Vision:</strong> Scikit-Image, OpenCV, MATLAB Image Toolboxes, 3D vision models (3D UNet, V-Net, SLAM, stereo matching, NeRFs).</li>
        <li><strong>Optimization:</strong> Quantization, knowledge distillation, pruning, CUDA kernel optimization, ONNX, TensorRT, OpenVINO.</li>
        <li><strong>Hardware Acceleration:</strong> FPGA implementation, real-time hardware systems, edge computing.</li>
      </ul>
    </section>

    <!-- SKILLS PROFICIENCY -->
<section id="proficiency">
  <h2 class="section-title">Skills Proficiency</h2>
  <div class="skills-grid">
    <div class="skill-pair">
      <div class="skill-item">
        <span class="skill-label">Python</span>
        <div class="bar-container">
          <div class="bar" style="width: 95%">95%</div>
        </div>
      </div>
      <div class="skill-item">
        <span class="skill-label">PyTorch</span>
        <div class="bar-container">
          <div class="bar" style="width: 90%">90%</div>
        </div>
      </div>
    </div>
    
    <div class="skill-pair">
      <div class="skill-item">
        <span class="skill-label">Keras</span>
        <div class="bar-container">
          <div class="bar" style="width: 90%">80%</div>
        </div>
      </div>
      <div class="skill-item">
        <span class="skill-label">Deep Learning</span>
        <div class="bar-container">
          <div class="bar" style="width: 90%">90%</div>
        </div>
      </div>
    </div>
    
    <div class="skill-pair">
      <div class="skill-item">
        <span class="skill-label">Multimodal AI</span>
        <div class="bar-container">
          <div class="bar" style="width: 85%">75%</div>
        </div>
      </div>
      <div class="skill-item">
        <span class="skill-label">Signal Processing</span>
        <div class="bar-container">
          <div class="bar" style="width: 85%">85%</div>
        </div>
      </div>
    </div>
    
    <div class="skill-pair">
      <div class="skill-item">
        <span class="skill-label">Computational Imaging</span>
        <div class="bar-container">
          <div class="bar" style="width: 85%">95%</div>
        </div>
      </div>
      <div class="skill-item">
        <span class="skill-label">NLP/LLM</span>
        <div class="bar-container">
          <div class="bar" style="width: 80%">80%</div>
        </div>
      </div>
    </div>
    
    <div class="skill-pair">
      <div class="skill-item">
        <span class="skill-label">Hardware Systems</span>
        <div class="bar-container">
          <div class="bar" style="width: 80%">80%</div>
        </div>
      </div>
      <div class="skill-item">
        <span class="skill-label">Computer Vision</span>
        <div class="bar-container">
          <div class="bar" style="width: 95%">95%</div>
        </div>
      </div>
    </div>
  </div>
</section>

<style>
  .skills-grid {
    display: flex;
    flex-direction: column;
    gap: 15px;
    margin-left: 20px;
  }
  
  .skill-pair {
    display: flex;
    gap: 30px;
  }
  
  .skill-item {
    flex: 1;
    min-width: 0;
  }
  
  .bar-container {
    height: 12px; /* Smaller bar height */
    margin-top: 3px;
  }
  
  .bar {
    height: 12px;
    line-height: 12px;
    font-size: 10px;
  }
  
  .skill-label {
    font-size: 0.9em;
    padding: 4px 8px;
  }
  
  @media (max-width: 600px) {
    .skill-pair {
      flex-direction: column;
      gap: 10px;
    }
  }
</style>

    <!-- PROFESSIONAL EXPERIENCE -->
    <section id="experience">
      <h2 class="section-title">Professional Experience</h2>
      
      <h3>Specialized HW and ML Engineer Intern — Amazon Lab126 | Sunnyvale, CA | 06/2025 – 09/2025</h3>
<ul>
  <li><strong>Goal-driven, resource-constrained design:</strong> Proposed and delivered color-mixing/display-enhancement solutions optimized for the limited compute/memory/power budget on Kindle Scribe, prioritizing small, fast, and reliable models over heavyweight DL.</li>

  <li><strong>Physics-based data engine:</strong> Generated a large, diverse synthetic dataset using physically inspired mixing, plus measured swatches, to cover pigments, paper textures, and stroke behaviors across the device gamut.</li>

  <li><strong>Model selection under scaling:</strong> Benchmarked compact learners end-to-end:
    <ul>
      <li><em>Polynomial regression</em> as a strong classical baseline, but observed instability and poor scalability in feature dimensionality & dataset size (fit time, numerical conditioning).</li>
      <li><em>Small MLPs</em> ( narrow width) emerged as the best accuracy–latency–memory trade-off, capturing nonlinearity without heavy runtime cost.</li>
    </ul>
  </li>


  <li><strong>Full developement & deployment:</strong> PyTorch → C++ inference (LibTorch/OpenVINO paths), with static-shape configs, operator fusion, thread pooling, and memory reuse.</li>

  <li><strong>Device integration:</strong> Embedded model into the Kindle Scribe pipeline with LUT export fallback, color-profile hooks, and guardrails for out-of-gamut inputs; exposed tunables for stroke sharpness and saturation ramp.</li>

  <li><strong>User study impact:</strong> Post-integration UX tests showed clear user preference for the new models vs. legacy blending (higher perceived realism and faster color convergence), supporting rollout decisions.</li>

  <li><strong>Key Outcomes:</strong> Production-ready, compact MLP models; physics-grounded data generation; complete PyTorch→C++ deployment; measurable UX wins on device.</li>
</ul>


      <h3>Research Scientist Intern -- Meta Reality Labs | Redmond, WA | 05/2024 – 11/2024</h3>
<ul>
  <li>Developed deep-learning models in PyTorch and Keras for polarization computational imaging in AR/MR/VR applications, improving reconstruction accuracy by 50% compared to SOTA baselines.</li>
  <li>On raw and sparse RGB-polarization (DoFP) data, built a calibrated ISP (flat-field, cross-talk, Stokes→AoLP/DoLP) and optimized GAN/ VAE/ ViT/ diffusion models for joint demosaicing–depolarization, inpainting, and super-resolution, yielding higher-fidelity RGB-polar reconstructions with fewer artifacts compared to all the baselines.</li>

  <li>3D rendering and digital twins using NeRF and 3D Gaussian Splatting, integrating polarization sensors/images (AoLP/DoLP) to enhance depth, surface normals, and material estimation for VR.</li>
  <li><strong>Key Skills:</strong> NeRF, 3D Gaussian Splatting, Polarization Imaging, GANs, VAEs, ViTs, Diffusion Models, Camera & Sensor Systems, 3D Reconstruction, Depth Estimation, HPC, Docker.</li>
</ul>



      <h3>AI Researcher & Team Manager -- TECVICO | Vancouver, Canada | 05/2020 – 11/2021</h3>
      <ul>
        <li>Led a team of AI researchers to develop medical imaging models.</li>
        <li>Designed and deployed CNN and transformer-based frameworks in Keras for healthcare anomaly detection.
          <ul>
            <li><strong>Head & Neck Cancer (MRI + CT):</strong> Built a multi-modal tumor segmentation and lymph-node detection pipeline (2.5D UNet/UNet++ + Swin-Transformer fusion) with deformable registration between MRI–CT; achieved oncologist-validated Dice improvements and integrated RT-structure exports (DICOM-RT) to assist radiation therapy planning and target delineation in clinical workflows.</li>
            <li><strong>Breast Imaging (Photon-Counting CT & Conventional CT):</strong> Developed lesion detection and tissue-density quantification using RetinaNet/YOLOv8 for candidate generation and ViT-based classifiers for BI-RADS-style triage; supported second-read decision support and dose/protocol optimization in industry PACS pipelines.</li>
            <li><strong>Anomaly Detection @ Scale:</strong> Deployed self-/weakly-supervised pretraining (SimCLR/MoCo, masked autoencoders) on mixed MRI/CT cohorts to flag out-of-distribution scans (artifacts, motion, protocol mismatch); used for worklist triage and automated QA in hospital imaging networks.</li>
          </ul>
        </li>
        
        <li><strong>Key Skills:</strong> Team Management, System Design, Medical Imaging, Anomaly Detection.</li>
      </ul>

      <h3>PhD Research Assistant -- University of Rochester | 01/2022 – 11/2025</h3>
      <ul>
        <ul>
          <li>Developed multimodal DL models in PyTorch for enhanced image-to-image translation in OCE (Optical Coherence Elastography), conditioning on acquisition metadata (e.g., scan depth, sampling rate, probe settings, tissue region, case age, awake/ sleep condition) via FiLM/adapters and cross-attention. Reduced domain shift across devices/sites and improved generalization on held-out cohorts without extra labels.</li>
        
          <li>Reconstructed brain stiffness maps from 3D shear-wave data with GANs, ViTs, and diffusion models as learned inversions (vs. classical Helmholtz/phase-gradient methods). Achieved lower error and higher structural fidelity (MAE/SSIM) while cutting inference latency to enable near–real-time visualization and integrated per-voxel uncertainty for safer clinical interpretation.</li>
        
          <li>Designed ViT, diffusion, and UNet-family models for breast cancer segmentation under resource constraints: semi-/weakly-supervised learning with consistency training and pseudo-labels, class-imbalance handling, and deployment optimizations (ONNX/OpenVINO, INT8 quantization, pruning). Targeted low-memory edge workstations typical of screening/triage workflows.</li>
        
          <li>Improved physics and signal processing based, H-Scan ultrasound analysis for abnormality detection by refining backscatter spectral-shift estimation, attenuation compensation, and band-limited matched filtering. Stabilized maps across depth/gain settings and combined physics features with DL heads for robust lesion highlighting.</li>
        
          <li><strong>Key Skills:</strong> Deep Learning (PyTorch), Multimodal DL, Generative Models (GAN/ViT/Diffusion), Model Optimization & Quantization (ONNX/OpenVINO/INT8), Signal Processing, Quantitative Imaging, OCT/OCE, Elastography, Ultrasound Data Acquisition, DICOM/Clinical Integration, Experimental Design & Validation.</li>
        </ul>
        

        <h3>MSc Research Assistant — Shahid Beheshti University | 09/2018–01/2021</h3>
        <ul>

          <li>
            <strong>Master’s Thesis — FPGA Super-Resolution (SR):</strong>
            Designed a fixed-point SR pipeline (deblurring → upsampling → refinement) on FPGA, using line buffers/BRAM tiling, DSP slice optimization, and AXI4-Stream DMA. Achieved stable timing closure at video rates; integrated camera input (MIPI/parallel) and LCD/HDMI output for on-device demos.
          </li>
          <li>
            <strong>Real-Time Stereo Vision on FPGA platform:</strong>
            Built a calibrated dual-camera pipeline (stereo <em>K, D, R, T</em>; rectification) and computed disparity using a
            <em>graph-cut</em> energy model (E = data + λ·smoothness) with α-expansion/β-swap moves, robust Potts smoothness,
            and occlusion handling via left–right consistency. Added sub-pixel refinement, median/bilateral filtering, and
            speckle removal. Converted disparity to metric depth (<em>Z = f·B/d</em>) and reprojected (<em>Q</em> matrix) to a
            colorized point cloud; downstream steps included plane/RANSAC fitting, normal estimation, and mesh reconstruction
            (Poisson/Ball-Pivoting) with optional multi-frame alignment via ICP for obstacle/scene understanding. Achieved
            <strong>real-time performance with high accuracy</strong> through parallelized cost-volume construction, and memory-aware scheduling—targeted for <strong>autonomous vehicle</strong> perception.
          </li>


          <li>
            <strong>FPGA-accelerated iris recognition (embedded vision):</strong>
            Implemented segmentation (integro-differential/Daugman), normalization, Gabor filtering, and template matching with
            Hamming distance in fixed-point. Achieved <em>60 FPS</em> at <em>1.8 W</em> with a <em>0.1% error rate</em> via pipelined
            architectures, resource sharing, and on-chip memory reuse.
          </li>
           
          <li>
            Built end-to-end lung CT pipelines in MATLAB: DICOM ingestion, resampling, lung/airway preprocessing, and
            classical ML (SVM/Random Forest with radiomics) alongside CNN baselines (2.5D/3D UNet variants). Implemented
            cross-validation, class-imbalance handling, and calibration to produce clinician-readable candidate lists.
          </li>
        
          <li>
            Developed TensorFlow transfer-learning models (ResNet/DenseNet backbones) for breast cancer detection on
            chest X-rays with explainability (Integrated Gradients) and uncertainty estimates. Standardized CXR
            preprocessing (de-identification, normalization, bone suppression) and reported FROC/sensitivity@FP consistent
            with clinical evaluation practices.
          </li>
        
        
          <li>
            Collaborated with clinicians/engineers to define labeling protocols, built reproducible training/eval scripts,
            and packaged models for edge deployment (C/C++/OpenCV) with automated tests and documentation.
          </li>
        
          <li>
            <strong>Key Skills:</strong> Machine/Deep Learning (MATLAB, TensorFlow), 2D/2.5D/3D CNNs, Radiomics, Explainable AI,
            Medical Image Processing (CT/CXR, DICOM), FPGA Design (VHDL/Verilog, HLS), Vivado/Quartus, Fixed-Point Quantization,
            DSP/BRAM optimization, AXI4/DMAs, OpenCV Optimization, Real-time Embedded & Edge Computing.
          </li>
        </ul>
    <!-- publications -->
    <section id="publications">
      <h2 class="section-title">Selected publications (3 out of 14 papers)</h2>
      <ul>
        <li>
          Khaledyan, Donya, <em>et&nbsp;al.</em> “WATUNet: a deep neural network for segmentation of volumetric sweep imaging ultrasound.”
          <em>Machine Learning: Science and Technology</em> <strong>5</strong>(1), 015042 (2024).
          <a href="https://www.google.com/search?q=WATUNet%3A+a+deep+neural+network+for+segmentation+of+volumetric+sweep+imaging+ultrasound+Machine+Learning%3A+Science+and+Technology+015042+2024" target="_blank" rel="noopener">View</a>
        </li>
    
        <li>
          Khaledyan, Donya, <em>et&nbsp;al.</em> “Enhancing breast ultrasound segmentation through fine-tuning and optimization techniques: Sharp Attention U-Net.”
          <em>PLOS ONE</em> <strong>18</strong>(12): e0289195 (2023).
          <a href="https://www.google.com/search?q=Enhancing+breast+ultrasound+segmentation+Sharp+Attention+UNet+PLOS+ONE+e0289195+2023" target="_blank" rel="noopener">View</a>
        </li>
    
        <li>
          Khaledyan, Donya, <em>et&nbsp;al.</em> “Low-cost implementation of bilinear and bicubic image interpolation for real-time image super-resolution.”
          In: <em>Proc. IEEE Global Humanitarian Technology Conference (GHTC)</em>, 2020.
          <a href="https://www.google.com/search?q=Low-cost+implementation+of+bilinear+and+bicubic+image+interpolation+for+real-time+image+super-resolution+GHTC+2020" target="_blank" rel="noopener">View</a>
        </li>
      </ul>
    </section>
        
    <!-- EDUCATION -->
    <section id="education">
      <h2 class="section-title">Education</h2>
      <ul>
        <li><strong>Ph.D.</strong> Electrical & Computer Engineering | University of Rochester | 2022 – 2025</li>
        <li><strong>M.Sc.</strong> Electrical & Computer Engineering | University of Rochester | 2022 – 2023</li>
        <li><strong>M.Sc.</strong> Electronics Digital Engineering | Shahid Beheshti University | 2018 – 2021</li>
        <li><strong>B.Sc.</strong> Electrical & Computer Engineering | Shiraz University of Technology | 2014 – 2018</li>
      </ul>
    </section>

    <!-- TEACHING EXPERIENCE -->
   <!-- TEACHING EXPERIENCE -->
<section id="teaching">
  <h2 class="section-title">Teaching Experience</h2>
  <h3>Teaching Assistant | University of Rochester & Shahid Beheshti University | 2020 – 2023</h3>
  <ul>
    <li>
      Served as TA for several courses, strengthening technical communication skills and deepening subject mastery through teaching:
      <strong>Medical Imaging, Signal Processing, FPGA, VLSI, Image Processing, Physics Electronics</strong>
    </li>
    <li>
      <strong>Skills Developed:</strong> 
      Conceptual reinforcement, adaptive instruction, curriculum development.
    </li>
  </ul>
</section>

  <!-- Scroll-to-top button -->
  <button class="scroll-to-top" id="scrollBtn">Top</button>

  <script>
    // Show scroll-to-top button when user scrolls down
    const scrollBtn = document.getElementById('scrollBtn');
    window.onscroll = function() {
      if (document.documentElement.scrollTop > 100 || document.body.scrollTop > 100) {
        scrollBtn.style.display = "block";
      } else {
        scrollBtn.style.display = "none";
      }
    };

    // Smoothly scroll to top
    scrollBtn.onclick = function() {
      window.scrollTo({
        top: 0,
        behavior: 'smooth'
      });
    };
  </script>

</body>
</html>

